{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Illustration of transforms\n",
        "\n",
        "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=green)\n",
        "\n",
        "**References:**\n",
        "- [![View filled on Github](https://img.shields.io/static/v1.svg?logo=pytorch&label=Website&message=Torchvision%20Transforms%20&color=lightgrey)](https://pytorch.org/vision/0.16/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py)\n",
        "- [![View filled on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=Albumentations%20Showcase%20&color=lightgrey)](https://github.com/albumentations-team/albumentations_examples/blob/master/notebooks/showcase.ipynb)\n",
        "- [![View filled on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=From%20Torchvision%20to%20Albumentations%20&color=lightgrey)](https://github.com/albumentations-team/albumentations_examples/blob/master/notebooks/migrating_from_torchvision_to_albumentations.ipynb)\n",
        "\n",
        "This example illustrates some of the various transforms available in `the\n",
        "torchvision.transforms.v2 module <transforms>`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
        "\n",
        "import random \n",
        "import numpy as np \n",
        "\n",
        "import torch\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.transforms.v2 import functional as F\n",
        "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
        "from torchvision import tv_tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_seed(seed: int = 42, rank: int = 0, deterministic: bool = False) -> None:\n",
        "    torch.manual_seed(seed + rank)\n",
        "    np.random.seed(seed + rank)\n",
        "    random.seed(seed + rank)\n",
        "    # GPU operations have a separate seed we also want to set\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed + rank)\n",
        "        torch.cuda.manual_seed_all(seed + rank)\n",
        "\n",
        "        # Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "        # We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "        torch.backends.cudnn.deterministic = deterministic\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "random_seed(deterministic=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot(imgs, row_title=None, **imshow_kwargs):\n",
        "    if not isinstance(imgs[0], list):\n",
        "        # Make a 2d grid even if there's just 1 row\n",
        "        imgs = [imgs]\n",
        "\n",
        "    num_rows = len(imgs)\n",
        "    num_cols = len(imgs[0])\n",
        "    _, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
        "    for row_idx, row in enumerate(imgs):\n",
        "        for col_idx, img in enumerate(row):\n",
        "            boxes = None\n",
        "            masks = None\n",
        "            if isinstance(img, tuple):\n",
        "                img, target = img\n",
        "                if isinstance(target, dict):\n",
        "                    boxes = target.get(\"boxes\")\n",
        "                    masks = target.get(\"masks\")\n",
        "                elif isinstance(target, tv_tensors.BoundingBoxes):\n",
        "                    boxes = target\n",
        "                else:\n",
        "                    raise ValueError(f\"Unexpected target type: {type(target)}\")\n",
        "            img = F.to_image(img)\n",
        "            if img.dtype.is_floating_point and img.min() < 0:\n",
        "                # Poor man's re-normalization for the colors to be OK-ish. This\n",
        "                # is useful for images coming out of Normalize()\n",
        "                img -= img.min()\n",
        "                img /= img.max()\n",
        "\n",
        "            img = F.to_dtype(img, torch.uint8, scale=True)\n",
        "            if boxes is not None:\n",
        "                img = draw_bounding_boxes(img, boxes, colors=\"yellow\", width=3)\n",
        "            if masks is not None:\n",
        "                img = draw_segmentation_masks(\n",
        "                    img,\n",
        "                    masks.to(torch.bool),\n",
        "                    colors=[\"green\"] * masks.shape[0],\n",
        "                    alpha=0.65,\n",
        "                )\n",
        "\n",
        "            ax = axs[row_idx, col_idx]\n",
        "            ax.imshow(img.permute(1, 2, 0).numpy(), **imshow_kwargs)\n",
        "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "\n",
        "    if row_title is not None:\n",
        "        for row_idx in range(num_rows):\n",
        "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
        "\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "orig_img = Image.open('./astronaut.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Geometric Transforms\n",
        "Geometric image transformation refers to the process of altering the geometric properties of an image,\n",
        "such as its shape, size, orientation, or position.\n",
        "It involves applying mathematical operations to the image pixels or coordinates to achieve the desired transformation.\n",
        "\n",
        "### Pad\n",
        "The :class:`~torchvision.transforms.Pad` transform\n",
        "(see also :func:`~torchvision.transforms.functional.pad`)\n",
        "pads all image borders with some pixel values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "padded_imgs = [v2.Pad(padding=padding)(orig_img) for padding in (3, 10, 30, 50)]\n",
        "plot([orig_img] + padded_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resize\n",
        "The :class:`~torchvision.transforms.Resize` transform\n",
        "(see also :func:`~torchvision.transforms.functional.resize`)\n",
        "resizes an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "resized_imgs = [v2.Resize(size=size)(orig_img) for size in (30, 50, 100, orig_img.size)]\n",
        "plot([orig_img] + resized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CenterCrop\n",
        "The :class:`~torchvision.transforms.CenterCrop` transform\n",
        "(see also :func:`~torchvision.transforms.functional.center_crop`)\n",
        "crops the given image at the center.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "center_crops = [v2.CenterCrop(size=size)(orig_img) for size in (30, 50, 100, orig_img.size)]\n",
        "plot([orig_img] + center_crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FiveCrop\n",
        "The :class:`~torchvision.transforms.FiveCrop` transform\n",
        "(see also :func:`~torchvision.transforms.functional.five_crop`)\n",
        "crops the given image into four corners and the central crop.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "(top_left, top_right, bottom_left, bottom_right, center) = v2.FiveCrop(size=(100, 100))(orig_img)\n",
        "plot([orig_img] + [top_left, top_right, bottom_left, bottom_right, center])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomPerspective\n",
        "The :class:`~torchvision.transforms.RandomPerspective` transform\n",
        "(see also :func:`~torchvision.transforms.functional.perspective`)\n",
        "performs random perspective transform on an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "perspective_transformer = v2.RandomPerspective(distortion_scale=0.6, p=1.0)\n",
        "perspective_imgs = [perspective_transformer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + perspective_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomRotation\n",
        "The :class:`~torchvision.transforms.RandomRotation` transform\n",
        "(see also :func:`~torchvision.transforms.functional.rotate`)\n",
        "rotates an image with random angle.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rotater = v2.RandomRotation(degrees=(0, 180))\n",
        "rotated_imgs = [rotater(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + rotated_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomAffine\n",
        "The :class:`~torchvision.transforms.RandomAffine` transform\n",
        "(see also :func:`~torchvision.transforms.functional.affine`)\n",
        "performs random affine transform on an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "affine_transfomer = v2.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))\n",
        "affine_imgs = [affine_transfomer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + affine_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ElasticTransform\n",
        "The :class:`~torchvision.transforms.ElasticTransform` transform\n",
        "(see also :func:`~torchvision.transforms.functional.elastic_transform`)\n",
        "Randomly transforms the morphology of objects in images and produces a\n",
        "see-through-water-like effect.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "elastic_transformer = v2.ElasticTransform(alpha=250.0)\n",
        "transformed_imgs = [elastic_transformer(orig_img) for _ in range(2)]\n",
        "plot([orig_img] + transformed_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomCrop\n",
        "The :class:`~torchvision.transforms.RandomCrop` transform\n",
        "(see also :func:`~torchvision.transforms.functional.crop`)\n",
        "crops an image at a random location.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cropper = v2.RandomCrop(size=(128, 128))\n",
        "crops = [cropper(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomResizedCrop\n",
        "The :class:`~torchvision.transforms.RandomResizedCrop` transform\n",
        "(see also :func:`~torchvision.transforms.functional.resized_crop`)\n",
        "crops an image at a random location, and then resizes the crop to a given\n",
        "size.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "resize_cropper = v2.RandomResizedCrop(size=(32, 32))\n",
        "resized_crops = [resize_cropper(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + resized_crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Photometric Transforms\n",
        "Photometric image transformation refers to the process of modifying the photometric properties of an image,\n",
        "such as its brightness, contrast, color, or tone.\n",
        "These transformations are applied to change the visual appearance of an image\n",
        "while preserving its geometric structure.\n",
        "\n",
        "Except :class:`~torchvision.transforms.Grayscale`, the following transforms are random,\n",
        "which means that the same transform\n",
        "instance will produce different result each time it transforms a given image.\n",
        "\n",
        "### Grayscale\n",
        "The :class:`~torchvision.transforms.Grayscale` transform\n",
        "(see also :func:`~torchvision.transforms.functional.to_grayscale`)\n",
        "converts an image to grayscale\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gray_img = v2.Grayscale()(orig_img)\n",
        "plot([orig_img, gray_img], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ColorJitter\n",
        "The :class:`~torchvision.transforms.ColorJitter` transform\n",
        "randomly changes the brightness, contrast, saturation, hue, and other properties of an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "jitter = v2.ColorJitter(brightness=.5, hue=.3)\n",
        "jittered_imgs = [jitter(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + jittered_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GaussianBlur\n",
        "The :class:`~torchvision.transforms.GaussianBlur` transform\n",
        "(see also :func:`~torchvision.transforms.functional.gaussian_blur`)\n",
        "performs gaussian blur transform on an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "blurrer = v2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.))\n",
        "blurred_imgs = [blurrer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + blurred_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomInvert\n",
        "The :class:`~torchvision.transforms.RandomInvert` transform\n",
        "(see also :func:`~torchvision.transforms.functional.invert`)\n",
        "randomly inverts the colors of the given image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inverter = v2.RandomInvert()\n",
        "invertered_imgs = [inverter(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + invertered_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomPosterize\n",
        "The :class:`~torchvision.transforms.RandomPosterize` transform\n",
        "(see also :func:`~torchvision.transforms.functional.posterize`)\n",
        "randomly posterizes the image by reducing the number of bits\n",
        "of each color channel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "posterizer = v2.RandomPosterize(bits=2)\n",
        "posterized_imgs = [posterizer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + posterized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomSolarize\n",
        "The :class:`~torchvision.transforms.RandomSolarize` transform\n",
        "(see also :func:`~torchvision.transforms.functional.solarize`)\n",
        "randomly solarizes the image by inverting all pixel values above\n",
        "the threshold.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solarizer = v2.RandomSolarize(threshold=192.0)\n",
        "solarized_imgs = [solarizer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + solarized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomAdjustSharpness\n",
        "The :class:`~torchvision.transforms.RandomAdjustSharpness` transform\n",
        "(see also :func:`~torchvision.transforms.functional.adjust_sharpness`)\n",
        "randomly adjusts the sharpness of the given image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sharpness_adjuster = v2.RandomAdjustSharpness(sharpness_factor=2)\n",
        "sharpened_imgs = [sharpness_adjuster(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + sharpened_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomAutocontrast\n",
        "The :class:`~torchvision.transforms.RandomAutocontrast` transform\n",
        "(see also :func:`~torchvision.transforms.functional.autocontrast`)\n",
        "randomly applies autocontrast to the given image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "autocontraster = v2.RandomAutocontrast()\n",
        "autocontrasted_imgs = [autocontraster(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + autocontrasted_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomEqualize\n",
        "The :class:`~torchvision.transforms.RandomEqualize` transform\n",
        "(see also :func:`~torchvision.transforms.functional.equalize`)\n",
        "randomly equalizes the histogram of the given image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "equalizer = v2.RandomEqualize()\n",
        "equalized_imgs = [equalizer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + equalized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augmentation Transforms\n",
        "The following transforms are combinations of multiple transforms,\n",
        "either geometric or photometric, or both.\n",
        "\n",
        "### AutoAugment\n",
        "The :class:`~torchvision.transforms.AutoAugment` transform\n",
        "automatically augments data based on a given auto-augmentation policy.\n",
        "See :class:`~torchvision.transforms.AutoAugmentPolicy` for the available policies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "policies = [v2.AutoAugmentPolicy.CIFAR10, v2.AutoAugmentPolicy.IMAGENET, v2.AutoAugmentPolicy.SVHN]\n",
        "augmenters = [v2.AutoAugment(policy) for policy in policies]\n",
        "imgs = [\n",
        "    [augmenter(orig_img) for _ in range(4)]\n",
        "    for augmenter in augmenters\n",
        "]\n",
        "row_title = [str(policy).split('.')[-1] for policy in policies]\n",
        "plot([[orig_img] + row for row in imgs], row_title=row_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandAugment\n",
        "The :class:`~torchvision.transforms.RandAugment` is an alternate version of AutoAugment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmenter = v2.RandAugment()\n",
        "imgs = [augmenter(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TrivialAugmentWide\n",
        "The :class:`~torchvision.transforms.TrivialAugmentWide` is an alternate implementation of AutoAugment.\n",
        "However, instead of transforming an image multiple times, it transforms an image only once\n",
        "using a random transform from a given list with a random strength number.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmenter = v2.TrivialAugmentWide()\n",
        "imgs = [augmenter(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AugMix\n",
        "The :class:`~torchvision.transforms.AugMix` transform interpolates between augmented versions of an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmenter = v2.AugMix()\n",
        "imgs = [augmenter(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Randomly-applied Transforms\n",
        "\n",
        "The following transforms are randomly-applied given a probability ``p``.  That is, given ``p = 0.5``,\n",
        "there is a 50% chance to return the original image, and a 50% chance to return the transformed image,\n",
        "even when called with the same transform instance!\n",
        "\n",
        "### RandomHorizontalFlip\n",
        "The :class:`~torchvision.transforms.RandomHorizontalFlip` transform\n",
        "(see also :func:`~torchvision.transforms.functional.hflip`)\n",
        "performs horizontal flip of an image, with a given probability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hflipper = v2.RandomHorizontalFlip(p=0.5)\n",
        "transformed_imgs = [hflipper(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + transformed_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomVerticalFlip\n",
        "The :class:`~torchvision.transforms.RandomVerticalFlip` transform\n",
        "(see also :func:`~torchvision.transforms.functional.vflip`)\n",
        "performs vertical flip of an image, with a given probability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vflipper = v2.RandomVerticalFlip(p=0.5)\n",
        "transformed_imgs = [vflipper(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + transformed_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomApply\n",
        "The :class:`~torchvision.transforms.RandomApply` transform\n",
        "randomly applies a list of transforms, with a given probability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "applier = v2.RandomApply(transforms=[v2.RandomCrop(size=(64, 64))], p=0.5)\n",
        "transformed_imgs = [applier(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + transformed_imgs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
